{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFXavBmKd_Ih"
      },
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "from torch import optim,nn \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oloeJdfSg13s"
      },
      "source": [
        "class Unet3D(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Unet3D,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv3d(in_channels=4,out_channels=32,kernel_size= (3,3,3),stride=(1,1,1),padding=(1,1,1))\n",
        "        self.conv2 = nn.Conv3d(in_channels=32, out_channels=64,kernel_size =(3,3,3),stride=(1,1,1),padding=(1,1,1))\n",
        "        self.maxpool1 = nn.MaxPool3d(kernel_size = (2,2,2))\n",
        "        self.conv3 = nn.Conv3d(in_channels=64,out_channels=64,kernel_size=(3,3,3),stride=(1,1,1),padding=(1,1,1))\n",
        "        self.conv4 = nn.Conv3d(in_channels=64,out_channels=128,kernel_size=(3,3,3),stride=(1,1,1),padding=(1,1,1))\n",
        "        self.upsample1 = nn.Upsample(scale_factor = (2,2,2))\n",
        "        self.conv5 = nn.Conv3d(in_channels=192,out_channels=64,kernel_size=(3,3,3),stride=(1,1,1),padding=(1,1,1))\n",
        "        self.conv6 = nn.Conv3d(in_channels=64,out_channels=64,kernel_size=(3,3,3),padding=(1,1,1),stride=(1,1,1))\n",
        "        self.fconv = nn.Conv3d(in_channels=64,out_channels=3,kernel_size=(1,1,1),stride=(1,1,1))\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        z1 = self.conv1(x)\n",
        "        a1 = F.relu(z1)\n",
        "\n",
        "        z2 = self.conv2(a1)\n",
        "        a2 = F.relu(z2)\n",
        "\n",
        "        z3 = self.maxpool1(a2)\n",
        "        z3 = self.conv3(z3)\n",
        "        a3 = F.relu(z3)\n",
        "\n",
        "        z4 = self.conv4(a3)\n",
        "        a4 = F.relu(z4)\n",
        "\n",
        "        z5 = self.upsample1(a4)\n",
        "        a5 = torch.cat([z5,a2],dim=1)\n",
        "\n",
        "        z6 = self.conv5(a5)\n",
        "        a6 = F.relu(z6)\n",
        "\n",
        "        z7 = self.conv6(a6)\n",
        "        a7 = F.relu(z7)\n",
        "\n",
        "        z8 = self.fconv(a7)\n",
        "        a8 = F.logsigmoid(z8)\n",
        "\n",
        "        return a8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToOyqziBg6ue",
        "outputId": "08649f03-d99e-46fe-a519-e0da92e4da97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "model = Unet3D()\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet3D(\n",
              "  (conv1): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (maxpool1): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv4): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (upsample1): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=nearest)\n",
              "  (conv5): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv6): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (fconv): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZe4S1PKhF_F",
        "outputId": "53d0098e-86e2-43b7-e7bb-dc07f85555d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.load_state_dict(torch.load('/content/AutoTumourModel.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5ussJIK0ov6"
      },
      "source": [
        "def standardize(image):\n",
        "    \n",
        "    standardized_image = np.zeros(image.shape)\n",
        "\n",
        "    for c in range(image.shape[0]):\n",
        "        for z in range(image.shape[3]):\n",
        "            image_slice = image[c,:,:,z]\n",
        "            centered = image_slice - np.mean(image_slice)\n",
        "            if np.std(centered) != 0:\n",
        "                centered_scaled = centered / np.std(centered)\n",
        "                standardized_image[c, :, :, z] = centered_scaled\n",
        "\n",
        "    return standardized_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0xwF-aqhblZ"
      },
      "source": [
        "def entire_scan(image,label,model):\n",
        "    model.eval()\n",
        "\n",
        "    model_label = np.zeros([3, 320, 320, 160])\n",
        "\n",
        "    for x in range(0, image.shape[0], 160):\n",
        "        for y in range(0, image.shape[1], 160):\n",
        "            for z in range(0, image.shape[2], 16):\n",
        "                patch = np.zeros([4, 160, 160, 16])\n",
        "                p = np.moveaxis(image[x: x + 160, y: y + 160, z:z + 16], 3, 0)\n",
        "                patch[:, 0:p.shape[1], 0:p.shape[2], 0:p.shape[3]] = p\n",
        "                patch = standardize(patch)\n",
        "                pred = model(torch.unsqueeze(torch.from_numpy(patch).float().cuda(),0))\n",
        "                pred = torch.exp(pred)\n",
        "                pred[pred>0.5] = 1.0\n",
        "                pred[pred<=0.5] = 0.0\n",
        "                pred = pred.cpu().detach().numpy()\n",
        "                model_label[:, x:x + p.shape[1],y:y + p.shape[2],z: z + p.shape[3]] += pred[0][:, :p.shape[1], :p.shape[2],:p.shape[3]]\n",
        "\n",
        "    model_label = np.moveaxis(model_label[:, 0:240, 0:240, 0:155], 0, 3)\n",
        "    model_label_reformatted = np.zeros((240, 240, 155, 4))\n",
        "    model_label_reformatted = to_categorical(label, num_classes=4).astype(np.uint8)\n",
        "    model_label_reformatted[:, :, :, 1:4] = model_label\n",
        "\n",
        "    return model_label_reformatted\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AgQ8057o6rl"
      },
      "source": [
        "import nibabel as nib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrMJMOJKhyQ5"
      },
      "source": [
        "img = np.array(nib.load('/content/BRATS_001.nii.gz').get_fdata())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnvmYj1Gx_Fa"
      },
      "source": [
        "label = np.array(nib.load('/content/label.nii.gz').get_fdata())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbPylyFumFY8"
      },
      "source": [
        "y = entire_scan(img,label,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73T6a2e9jnda"
      },
      "source": [
        "torch.save(y,'y_pred.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}